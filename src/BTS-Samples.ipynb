{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BTS and Sampling**\n",
    "This project explores the network-style relationship between BTS and other artists based on the samples used in their music. The objective of this project is to understand the relationship between artist and influence, creating a complex relationship across genres and geographies.\n",
    "\n",
    "In this project, I will be using a few specific terms to refer to songs and samples. They are as follows:\n",
    "- **sample** - A sample is a recorded sound taken from its original context and applied to a new context.\n",
    "- **sampled** - The action of using a sample. *They sampled <Sample Source> in <Song Containing Sample>.\n",
    "- **song** - For the context of this project, *all songs contain samples, but not all samples are songs*.\n",
    "\n",
    "In practice, sentences should take the following form:\n",
    "\n",
    "- BTS *sampled* **Here We Go (Live at the Funhouse) by Run-DMC** in the *song* **호르몬 전쟁 War of Hormone\n",
    "호르몬 전쟁 War of Hormone**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created: May 17, 2023\n",
    "# Author: Brendan Keane (GitHub @brendanwilliam)\n",
    "# Purpose: Create a list of CSS selectors to pull sample data\n",
    "\n",
    "# Imports\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#==================== Global constants ====================#\n",
    "EXPORT_PATH = \"../src/data/raw/\"\n",
    "ARTIST = \"BTS\"\n",
    "ARTIST_PAGE = \"https://whosampled.com/{}/samples/\"\n",
    "ARTIST_SAMPLES = ARTIST_PAGE.format(ARTIST) + '?sp={}'\n",
    "ROOT_URL = \"https://www.whosampled.com\"\n",
    "HEADERS = {\n",
    "    'Access-Control-Allow-Origin': '*',\n",
    "    'Access-Control-Allow-Methods': 'GET',\n",
    "    'Access-Control-Allow-Headers': 'Content-Type',\n",
    "    'Access-Control-Max-Age': '3600',\n",
    "    'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These functions gather all samples used by a specified artist\n",
    "`nav_all_pages` works through all pages from a given URL and performs the specified function on each page. This function is used throughout this project to doeal with pages with more than 10 results.\n",
    "\n",
    "`get_sample_pages` scrapes all the sample URLs on a page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current page:\thttps://whosampled.com/BTS/samples/?sp=1\n",
      "Current page:\thttps://whosampled.com/BTS/samples/?sp=2\n",
      "Number of sample URL paths collected:  23\n"
     ]
    }
   ],
   "source": [
    "# Works through all pages from a given WhoSampled artist/track page\n",
    "def nav_all_pages(url, func, dt):\n",
    "  cur_page = 1\n",
    "  while True:\n",
    "    # This is to help people see where information is coming from in this project\n",
    "    cur_url = url.format(cur_page)\n",
    "    print('Current page:\\t' + cur_url)\n",
    "\n",
    "    # Handles error of a page having less than 10 results by modifying the URL\n",
    "    response = requests.get(cur_url, headers=HEADERS)\n",
    "    if response.status_code != 200:\n",
    "      cur_url = cur_url[:-13]\n",
    "      response = requests.get(cur_url, headers=HEADERS)\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    dt = func(soup, dt, cur_url)\n",
    "\n",
    "    # Finding the next page element\n",
    "    next_page = soup.find('span', class_='next')\n",
    "\n",
    "    if not next_page:\n",
    "      break\n",
    "    else:\n",
    "      cur_page += 1\n",
    "      time.sleep(random.randint(1, 2))\n",
    "  return dt\n",
    "\n",
    "# Returns a list of sample pages from a given WhoSampled artist page\n",
    "def get_sample_pages(soup, page_list, cur_page):\n",
    "  for sample in soup.find_all('a', class_='connectionName playIcon'):\n",
    "    page_list.append(sample.get('href'))\n",
    "  return page_list\n",
    "\n",
    "def get_sample_source(url):\n",
    "  cur_url = ROOT_URL + url\n",
    "  response = requests.get(cur_url, headers=HEADERS)\n",
    "  soup = BeautifulSoup(response.content, 'html.parser')\n",
    "  sample_element = soup.find('div', id='sampleWrap_source')\n",
    "  sample_source = sample_element.find('a').get('href')\n",
    "  return sample_source\n",
    "\n",
    "def get_all_sample_sources(urls):\n",
    "  sample_sources = []\n",
    "  for url in urls:\n",
    "    sample_sources.append(get_sample_source(url))\n",
    "\n",
    "  return list(set(sample_sources))\n",
    "\n",
    "\n",
    "# Creates a list of all samples an artist has used\n",
    "pages = nav_all_pages(ARTIST_SAMPLES, get_sample_pages, [])\n",
    "\n",
    "# Returns a Set of URLs from a list of samples\n",
    "sources = get_all_sample_sources(pages)\n",
    "\n",
    "print(\"Number of sample URL paths collected: \", str(len(sources)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Creating a dataset of songs and samples**\n",
    "Now that we have the URLs for every sample used by an artist, we can create a dataset of all songs containing the sample. This dataset is the basis of our network, as the connection between song and sample is that of two nodes connected by an edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current page:\thttps://www.whosampled.com/BTS/Intro%3A-2-Cool-4-Skool/sampled/?cp=1\n",
      "Current page:\thttps://www.whosampled.com/BTS/Best-of-Me-(Japanese-Version)/sampled/?cp=1\n",
      "Current page:\thttps://www.whosampled.com/BTS/Outro%3A-Luv-in-Skool/sampled/?cp=1\n",
      "Current page:\thttps://www.whosampled.com/Urban-Zakapa/%EC%BB%A4%ED%94%BC%EB%A5%BC-%EB%A7%88%EC%8B%9C%EA%B3%A0/sampled/?cp=1\n",
      "Current page:\thttps://www.whosampled.com/Keb%27-Mo%27/Am-I-Wrong/sampled/?cp=1\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=1\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=2\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=3\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=4\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=5\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=6\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=7\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=8\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=9\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=10\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=11\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=12\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=13\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=14\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=15\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=16\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=17\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=18\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=19\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=20\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=21\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=22\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=23\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=24\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=25\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=26\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=27\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=28\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=29\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=30\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=31\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=32\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=33\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=34\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=35\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=36\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=37\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=38\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=39\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=40\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=41\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=42\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=43\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=44\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=45\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=46\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=47\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=48\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=49\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=50\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=51\n",
      "Current page:\thttps://www.whosampled.com/Mountain/Long-Red/sampled/?cp=52\n",
      "Current page:\thttps://www.whosampled.com/The-Mad-Lads/Get-Out-of-My-Life,-Woman/sampled/?cp=1\n",
      "Current page:\thttps://www.whosampled.com/The-Mad-Lads/Get-Out-of-My-Life,-Woman/sampled/?cp=2\n",
      "Current page:\thttps://www.whosampled.com/The-Mad-Lads/Get-Out-of-My-Life,-Woman/sampled/?cp=3\n",
      "Current page:\thttps://www.whosampled.com/SFB-(2)/Strangers/sampled/?cp=1\n",
      "Current page:\thttps://www.whosampled.com/The-Game/El-Chapo/sampled/?cp=1\n",
      "Current page:\thttps://www.whosampled.com/BTS/Save-ME/sampled/?cp=1\n",
      "Current page:\thttps://www.whosampled.com/Koji-Kondo/Super-Mario-Bros.-Sound-Effects/sampled/?cp=1\n",
      "Current page:\thttps://www.whosampled.com/Koji-Kondo/Super-Mario-Bros.-Sound-Effects/sampled/?cp=2\n",
      "Current page:\thttps://www.whosampled.com/Koji-Kondo/Super-Mario-Bros.-Sound-Effects/sampled/?cp=3\n",
      "Current page:\thttps://www.whosampled.com/Koji-Kondo/Super-Mario-Bros.-Sound-Effects/sampled/?cp=4\n",
      "Current page:\thttps://www.whosampled.com/Myungsoo-Shin/LOVE-YOURSELF-Highlight-Reel-%27%E8%BD%89%27/sampled/?cp=1\n",
      "Current page:\thttps://www.whosampled.com/BTS/Intro%3A-Skool-Luv-Affair/sampled/?cp=1\n",
      "Current page:\thttps://www.whosampled.com/j-hope/Airplane/sampled/?cp=1\n",
      "Current page:\thttps://www.whosampled.com/Manuel-De-Falla/La-Vida-Breve/sampled/?cp=1\n",
      "Current page:\thttps://www.whosampled.com/K-Tel/Touch-Steps-Two-Beat-Turn-Freestyle-Routine/sampled/?cp=1\n",
      "Current page:\thttps://www.whosampled.com/J.-Cole/Born-Sinner/sampled/?cp=1\n",
      "Current page:\thttps://www.whosampled.com/YouTube/Crazy-German-Kid/sampled/?cp=1\n",
      "Current page:\thttps://www.whosampled.com/Shinhwa/T.O.P.-Twinkling-of-Paradise/sampled/?cp=1\n",
      "Current page:\thttps://www.whosampled.com/Shinhwa/This-Love/sampled/?cp=1\n",
      "Current page:\thttps://www.whosampled.com/BTS/Intro%3A-O!RUL8,2%3F/sampled/?cp=1\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=1\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=2\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=3\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=4\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=5\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=6\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=7\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=8\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=9\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=10\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=11\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=12\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=13\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=14\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=15\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=16\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=17\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=18\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=19\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=20\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=21\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=22\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=23\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=24\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=25\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=26\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=27\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=28\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=29\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=30\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=31\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=32\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=33\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=34\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=35\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=36\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=37\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=38\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=39\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=40\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=41\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=42\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=43\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=44\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=45\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=46\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=47\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=48\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=49\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=50\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=51\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=52\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=53\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=54\n",
      "Current page:\thttps://www.whosampled.com/Run-DMC/Here-We-Go-(Live-at-the-Funhouse)/sampled/?cp=55\n",
      "Current page:\thttps://www.whosampled.com/%EC%86%A1%EC%B0%BD%EC%8B%9D-(Song-Chang-Sik)/%EC%99%9C-%EB%B6%88%EB%9F%AC/sampled/?cp=1\n"
     ]
    }
   ],
   "source": [
    "# URL for all songs containing a specific sample\n",
    "# Format:\n",
    "  # Field 1: Sample URL\n",
    "  # Field 2: Page number\n",
    "SAMPLE_URL = 'https://www.whosampled.com{}sampled/?cp={}'\n",
    "\n",
    "# Gathers information about every song containing a sample.\n",
    "# Takes in the sample URL and a DataFrame and returns a DataFrame with\n",
    "# all songs containing the specified sample.\n",
    "def get_all_sample_uses(url, df):\n",
    "  cur_url = SAMPLE_URL.format(url, '{}')\n",
    "  df = nav_all_pages(cur_url, get_sample_uses, df)\n",
    "  return df\n",
    "\n",
    "# This function is passed into `nav_all_pages` so that it's executed on every\n",
    "# page visited.\n",
    "# Takes in the BeautifulSoup data from the page, a DataFrame, and the URL of the\n",
    "# song containing the sample.\n",
    "# Returns the DataFrame with the `title`, `artist`, `year`, and `sample` (URL)\n",
    "# added as a new row to the DataFrame. On a full page, this will add 10 entries\n",
    "# to the DataFrame.\n",
    "def get_sample_uses(soup, df, cur_page):\n",
    "\n",
    "  substring = \"Was sampled in\"\n",
    "  found_section = None\n",
    "  sections = soup.find_all('section')\n",
    "\n",
    "  # Makes sure the section is for samples\n",
    "  for section in sections:\n",
    "    header = section.find('span')\n",
    "\n",
    "    if substring in header.text:\n",
    "      found_section = section\n",
    "      break\n",
    "\n",
    "  if found_section is  None:\n",
    "    print(\"Error: Unable to find instances of this song being sampled.\")\n",
    "    exit()\n",
    "\n",
    "  # Loops through all entries on a page\n",
    "  for sample in found_section.find_all('div', class_='listEntry sampleEntry'):\n",
    "\n",
    "    # Scrapes the desired information\n",
    "    title = sample.find('a', class_='trackName playIcon').text.strip()\n",
    "    artist = sample.find('span', class_='trackArtist').text.strip()\n",
    "    style = sample.find('span', class_='topItem').text.strip()\n",
    "    sample_path = re.sub(r'sampled/\\?cp=\\d+', '', cur_page)\n",
    "\n",
    "    # Handling if a genre does not exist\n",
    "    try:\n",
    "      elem = sample.find('span', class_='bottomItem').text.strip()\n",
    "      if elem:\n",
    "        genre = elem\n",
    "      else:\n",
    "        genre = ''\n",
    "    except AttributeError:\n",
    "      genre = ''\n",
    "\n",
    "    # Adds information to DataFrame\n",
    "    new_entry = pd.DataFrame({\n",
    "      'title': [title],\n",
    "      'artist': [' '.join(artist.split()[1:-1])],\n",
    "      'year': [artist.split()[-1][1:-1]],\n",
    "      'genre': [genre],\n",
    "      'style': [style],\n",
    "      'sample': [sample_path]\n",
    "    })\n",
    "    df = pd.concat([df, new_entry], ignore_index=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "\n",
    "# Takes in a list of sample URLs and saves a `.csv` of all songs that contain the sample.\n",
    "def create_shared_sample_df(sources):\n",
    "\n",
    "  # Create the DataFrame\n",
    "  df = pd.DataFrame(columns=['title', 'artist', 'year', 'sample'])\n",
    "\n",
    "  # Loop through all URLs\n",
    "  for source in sources:\n",
    "\n",
    "    # Reset the df variable to include all newly added songs\n",
    "    df = get_all_sample_uses(source, df)\n",
    "    time.sleep(random.randint(1, 3))\n",
    "\n",
    "    # Save current state\n",
    "    df.to_csv(EXPORT_PATH + 'songs_w_samples_output.csv')\n",
    "\n",
    "  # Final export\n",
    "  df.to_csv(EXPORT_PATH + 'songs_w_samples_dataset.csv')\n",
    "\n",
    "create_shared_sample_df(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   title artist  year  \\\n",
      "0  Intro: 2 Cool 4 Skool    BTS  2013   \n",
      "\n",
      "                                              sample       genre   style  \n",
      "0  https://whosampled.com/BTS/Intro%3A-2-Cool-4-S...  Rock / Pop  Source  \n",
      "                           title artist  year  \\\n",
      "0  Best of Me (Japanese Version)    BTS  2018   \n",
      "\n",
      "                                              sample       genre   style  \n",
      "0  https://whosampled.com/BTS/Best-of-Me-(Japanes...  Rock / Pop  Source  \n",
      "                 title artist  year  \\\n",
      "0  Outro: Luv in Skool    BTS  2013   \n",
      "\n",
      "                                              sample       genre   style  \n",
      "0  https://whosampled.com/BTS/Outro%3A-Luv-in-Skool/  Rock / Pop  Source  \n",
      "     title        artist  year  \\\n",
      "0  커피를 마시고  Urban Zakapa  2009   \n",
      "\n",
      "                                              sample       genre   style  \n",
      "0  https://whosampled.com/Urban-Zakapa/%EC%BB%A4%...  Rock / Pop  Source  \n",
      "        title    artist  year  \\\n",
      "0  Am I Wrong  Keb' Mo'  1994   \n",
      "\n",
      "                                            sample         genre   style  \n",
      "0  https://whosampled.com/Keb%27-Mo%27/Am-I-Wrong/  Jazz / Blues  Source  \n",
      "      title    artist  year                                     sample  \\\n",
      "0  Long Red  Mountain  1972  https://whosampled.com/Mountain/Long-Red/   \n",
      "\n",
      "        genre   style  \n",
      "0  Rock / Pop  Source  \n",
      "                       title        artist  year  \\\n",
      "0  Get Out of My Life, Woman  The Mad Lads  1966   \n",
      "\n",
      "                                              sample                genre  \\\n",
      "0  https://whosampled.com/The-Mad-Lads/Get-Out-of...  Soul / Funk / Disco   \n",
      "\n",
      "    style  \n",
      "0  Source  \n",
      "       title   artist  year                                     sample  \\\n",
      "0  Strangers  SFB (2)  2015  https://whosampled.com/SFB-(2)/Strangers/   \n",
      "\n",
      "                 genre   style  \n",
      "0  Hip-Hop / Rap / R&B  Source  \n",
      "      title    artist  year                                     sample  \\\n",
      "0  El Chapo  The Game  2015  https://whosampled.com/The-Game/El-Chapo/   \n",
      "\n",
      "                 genre   style  \n",
      "0  Hip-Hop / Rap / R&B  Source  \n",
      "     title artist  year                               sample       genre  \\\n",
      "0  Save ME    BTS  2016  https://whosampled.com/BTS/Save-ME/  Rock / Pop   \n",
      "\n",
      "    style  \n",
      "0  Source  \n",
      "                             title      artist  year  \\\n",
      "0  Super Mario Bros. Sound Effects  Koji Kondo  1985   \n",
      "\n",
      "                                              sample  genre   style  \n",
      "0  https://whosampled.com/Koji-Kondo/Super-Mario-...  Other  Source  \n",
      "                              title         artist  year  \\\n",
      "0  LOVE YOURSELF Highlight Reel '轉'  Myungsoo Shin  2017   \n",
      "\n",
      "                                              sample  genre   style  \n",
      "0  https://whosampled.com/Myungsoo-Shin/LOVE-YOUR...  Other  Source  \n",
      "                     title artist  year  \\\n",
      "0  Intro: Skool Luv Affair    BTS  2014   \n",
      "\n",
      "                                              sample                genre  \\\n",
      "0  https://whosampled.com/BTS/Intro%3A-Skool-Luv-...  Hip-Hop / Rap / R&B   \n",
      "\n",
      "    style  \n",
      "0  Source  \n",
      "      title  artist  year                                   sample  \\\n",
      "0  Airplane  j-hope  2018  https://whosampled.com/j-hope/Airplane/   \n",
      "\n",
      "                 genre   style  \n",
      "0  Hip-Hop / Rap / R&B  Source  \n",
      "           title           artist  year  \\\n",
      "0  La Vida Breve  Manuel De Falla  1913   \n",
      "\n",
      "                                              sample  genre   style  \n",
      "0  https://whosampled.com/Manuel-De-Falla/La-Vida...  Other  Source  \n",
      "                                             title artist  year  \\\n",
      "0  Touch Steps / Two Beat Turn / Freestyle Routine  K-Tel  1978   \n",
      "\n",
      "                                              sample        genre   style  \n",
      "0  https://whosampled.com/K-Tel/Touch-Steps-Two-B...  Spoken Word  Source  \n",
      "         title   artist  year                                       sample  \\\n",
      "0  Born Sinner  J. Cole  2013  https://whosampled.com/J.-Cole/Born-Sinner/   \n",
      "\n",
      "                 genre   style  \n",
      "0  Hip-Hop / Rap / R&B  Source  \n",
      "              title   artist  year  \\\n",
      "0  Crazy German Kid  YouTube  2006   \n",
      "\n",
      "                                             sample        genre   style  \n",
      "0  https://whosampled.com/YouTube/Crazy-German-Kid/  Spoken Word  Source  \n",
      "                          title   artist  year  \\\n",
      "0  T.O.P. Twinkling of Paradise  Shinhwa  1999   \n",
      "\n",
      "                                              sample                genre  \\\n",
      "0  https://whosampled.com/Shinhwa/T.O.P.-Twinklin...  Hip-Hop / Rap / R&B   \n",
      "\n",
      "    style  \n",
      "0  Source  \n",
      "       title   artist  year                                     sample  \\\n",
      "0  This Love  Shinhwa  2013  https://whosampled.com/Shinhwa/This-Love/   \n",
      "\n",
      "                genre   style  \n",
      "0  Electronic / Dance  Source  \n",
      "              title artist  year  \\\n",
      "0  Intro: O!RUL8,2?    BTS  2013   \n",
      "\n",
      "                                             sample       genre   style  \n",
      "0  https://whosampled.com/BTS/Intro%3A-O!RUL8,2%3F/  Rock / Pop  Source  \n",
      "                               title   artist  year  \\\n",
      "0  Here We Go (Live at the Funhouse)  Run-DMC  1985   \n",
      "\n",
      "                                              sample                genre  \\\n",
      "0  https://whosampled.com/Run-DMC/Here-We-Go-(Liv...  Hip-Hop / Rap / R&B   \n",
      "\n",
      "    style  \n",
      "0  Source  \n",
      "  title                artist  year  \\\n",
      "0  왜 불러  송창식 (Song Chang Sik)  1975   \n",
      "\n",
      "                                              sample           genre   style  \n",
      "0  https://whosampled.com/%EC%86%A1%EC%B0%BD%EC%8...  Country / Folk  Source  \n"
     ]
    }
   ],
   "source": [
    "# Takes in a list of URLs and returns song information\n",
    "\n",
    "def get_song_details(url, df):\n",
    "  cur_url = ROOT_URL + url\n",
    "  res = requests.get(cur_url, headers=HEADERS)\n",
    "  soup = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "  title = soup.find('meta', itemprop='name')[\"content\"].strip()\n",
    "  name = soup.find('span', itemprop='byArtist').find('meta', itemprop='name')[\"content\"].strip()\n",
    "  year = soup.find('meta', itemprop='datePublished')[\"content\"].strip()\n",
    "  genre = soup.find('span', itemprop='genre').text.strip()\n",
    "\n",
    "  new_entry = pd.DataFrame({\n",
    "    'title': [title],\n",
    "    'artist': [name],\n",
    "    'year': [year],\n",
    "    'sample': [cur_url],\n",
    "    'genre': [genre],\n",
    "    'style': 'Source'\n",
    "\n",
    "  })\n",
    "  print(new_entry)\n",
    "  df = pd.concat([df, new_entry], ignore_index=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "def create_song_df(url_list):\n",
    "\n",
    "  df = pd.DataFrame(columns=['title', 'artist', 'year', 'genre', 'style', 'sample_path'])\n",
    "  for url in url_list:\n",
    "    df = get_song_details(url, df)\n",
    "    time.sleep(random.randint(1, 2))\n",
    "\n",
    "  return df\n",
    "\n",
    "sample_df = create_song_df(sources)\n",
    "sample_df.to_csv(EXPORT_PATH + 'samples_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Network DataFrame\n",
    "Now that we have data for songs and samples, we will now create two DataFrames. First, we will create a DataFrame with all songs within this project. This is so that we can reference every song by an ID.\n",
    "\n",
    "Second, we will create a network based on source, target, and value attributes. The result will be a network from our ID values which we will later populate with metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv('data/raw/samples_dataset.csv')\n",
    "song_w_samples_df = pd.read_csv('data/raw/songs_w_samples_dataset.csv')\n",
    "\n",
    "song_df = pd.concat([sample_df, song_w_samples_df], ignore_index=True)\n",
    "song_df = song_df.drop('Unnamed: 0', axis=1)\n",
    "song_df.to_csv('data/processed/song_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>year</th>\n",
       "      <th>genre</th>\n",
       "      <th>style</th>\n",
       "      <th>sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>230</td>\n",
       "      <td>Brooklyn Blew Up the Bridge</td>\n",
       "      <td>MC Mitchski</td>\n",
       "      <td>1987</td>\n",
       "      <td>Hip-Hop / Rap / R&amp;B</td>\n",
       "      <td>Vocals / Lyrics</td>\n",
       "      <td>https://www.whosampled.com/Mountain/Long-Red/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>429</td>\n",
       "      <td>That's How I'm Livin' (On the Rox Remix)</td>\n",
       "      <td>Ice-T</td>\n",
       "      <td>1993</td>\n",
       "      <td>Hip-Hop / Rap / R&amp;B</td>\n",
       "      <td>Drums</td>\n",
       "      <td>https://www.whosampled.com/Mountain/Long-Red/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>1800</td>\n",
       "      <td>How Could You</td>\n",
       "      <td>J Foe</td>\n",
       "      <td>1990</td>\n",
       "      <td>Hip-Hop / Rap / R&amp;B</td>\n",
       "      <td>Vocals / Lyrics</td>\n",
       "      <td>https://www.whosampled.com/Run-DMC/Here-We-Go-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>99</td>\n",
       "      <td>Wussup Wit the Luv</td>\n",
       "      <td>Digital Underground feat. 2Pac</td>\n",
       "      <td>1993</td>\n",
       "      <td>Hip-Hop / Rap / R&amp;B</td>\n",
       "      <td>Vocals / Lyrics</td>\n",
       "      <td>https://www.whosampled.com/Mountain/Long-Red/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>1312</td>\n",
       "      <td>Back Stage Pacin'</td>\n",
       "      <td>Brother Ali</td>\n",
       "      <td>2003</td>\n",
       "      <td>Hip-Hop / Rap / R&amp;B</td>\n",
       "      <td>Multiple Elements</td>\n",
       "      <td>https://www.whosampled.com/Run-DMC/Here-We-Go-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                     title  \\\n",
       "207    230               Brooklyn Blew Up the Bridge   \n",
       "406    429  That's How I'm Livin' (On the Rox Remix)   \n",
       "1777  1800                             How Could You   \n",
       "76      99                        Wussup Wit the Luv   \n",
       "1289  1312                         Back Stage Pacin'   \n",
       "\n",
       "                              artist  year                genre  \\\n",
       "207                      MC Mitchski  1987  Hip-Hop / Rap / R&B   \n",
       "406                            Ice-T  1993  Hip-Hop / Rap / R&B   \n",
       "1777                           J Foe  1990  Hip-Hop / Rap / R&B   \n",
       "76    Digital Underground feat. 2Pac  1993  Hip-Hop / Rap / R&B   \n",
       "1289                     Brother Ali  2003  Hip-Hop / Rap / R&B   \n",
       "\n",
       "                  style                                             sample  \n",
       "207     Vocals / Lyrics      https://www.whosampled.com/Mountain/Long-Red/  \n",
       "406               Drums      https://www.whosampled.com/Mountain/Long-Red/  \n",
       "1777    Vocals / Lyrics  https://www.whosampled.com/Run-DMC/Here-We-Go-...  \n",
       "76      Vocals / Lyrics      https://www.whosampled.com/Mountain/Long-Red/  \n",
       "1289  Multiple Elements  https://www.whosampled.com/Run-DMC/Here-We-Go-...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/processed/nodes_unique.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'artist', 'year', 'genre', 'style', 'sample'], dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = df\n",
    "rdf = rdf.drop('id', axis=1)\n",
    "rdf.to_csv('data/processed/nodes_unique.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>year</th>\n",
       "      <th>genre</th>\n",
       "      <th>style</th>\n",
       "      <th>sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>594</td>\n",
       "      <td>Monkey See, Monkey Do</td>\n",
       "      <td>C.E.B.</td>\n",
       "      <td>2016</td>\n",
       "      <td>Hip-Hop / Rap / R&amp;B</td>\n",
       "      <td>Drums</td>\n",
       "      <td>https://www.whosampled.com/Mountain/Long-Red/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>348</td>\n",
       "      <td>Bus Dat Ass</td>\n",
       "      <td>King Tee feat. Tha Alkaholiks</td>\n",
       "      <td>1992</td>\n",
       "      <td>Hip-Hop / Rap / R&amp;B</td>\n",
       "      <td>Vocals / Lyrics</td>\n",
       "      <td>https://www.whosampled.com/Mountain/Long-Red/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>641</td>\n",
       "      <td>Come Il Sole</td>\n",
       "      <td>Ensi</td>\n",
       "      <td>2012</td>\n",
       "      <td>Hip-Hop / Rap / R&amp;B</td>\n",
       "      <td>Vocals / Lyrics</td>\n",
       "      <td>https://www.whosampled.com/Mountain/Long-Red/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>953</td>\n",
       "      <td>Abyssal Dependence</td>\n",
       "      <td>Zuntata</td>\n",
       "      <td>2011</td>\n",
       "      <td>Electronic / Dance</td>\n",
       "      <td>Vocals / Lyrics</td>\n",
       "      <td>https://www.whosampled.com/YouTube/Crazy-Germa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>615</td>\n",
       "      <td>No Risk No Reward</td>\n",
       "      <td>LMNO</td>\n",
       "      <td>2013</td>\n",
       "      <td>Hip-Hop / Rap / R&amp;B</td>\n",
       "      <td>Vocals / Lyrics</td>\n",
       "      <td>https://www.whosampled.com/Mountain/Long-Red/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                  title                         artist  year  \\\n",
       "617         594  Monkey See, Monkey Do                         C.E.B.  2016   \n",
       "371         348            Bus Dat Ass  King Tee feat. Tha Alkaholiks  1992   \n",
       "664         641           Come Il Sole                           Ensi  2012   \n",
       "976         953     Abyssal Dependence                        Zuntata  2011   \n",
       "638         615      No Risk No Reward                           LMNO  2013   \n",
       "\n",
       "                   genre            style  \\\n",
       "617  Hip-Hop / Rap / R&B            Drums   \n",
       "371  Hip-Hop / Rap / R&B  Vocals / Lyrics   \n",
       "664  Hip-Hop / Rap / R&B  Vocals / Lyrics   \n",
       "976   Electronic / Dance  Vocals / Lyrics   \n",
       "638  Hip-Hop / Rap / R&B  Vocals / Lyrics   \n",
       "\n",
       "                                                sample  \n",
       "617      https://www.whosampled.com/Mountain/Long-Red/  \n",
       "371      https://www.whosampled.com/Mountain/Long-Red/  \n",
       "664      https://www.whosampled.com/Mountain/Long-Red/  \n",
       "976  https://www.whosampled.com/YouTube/Crazy-Germa...  \n",
       "638      https://www.whosampled.com/Mountain/Long-Red/  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "can only convert an array of size 1 to a Python scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/brendankeane/whosampled-artist/src/BTS-Samples.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brendankeane/whosampled-artist/src/BTS-Samples.ipynb#X13sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     net \u001b[39m=\u001b[39m add_sample_to_network(sample_df, net)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brendankeane/whosampled-artist/src/BTS-Samples.ipynb#X13sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m net\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/brendankeane/whosampled-artist/src/BTS-Samples.ipynb#X13sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m net \u001b[39m=\u001b[39m make_sample_network(df)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brendankeane/whosampled-artist/src/BTS-Samples.ipynb#X13sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m net\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mdata/processed/edges.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/Users/brendankeane/whosampled-artist/src/BTS-Samples.ipynb Cell 14\u001b[0m in \u001b[0;36mmake_sample_network\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brendankeane/whosampled-artist/src/BTS-Samples.ipynb#X13sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mfor\u001b[39;00m sample \u001b[39min\u001b[39;00m sample_list:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brendankeane/whosampled-artist/src/BTS-Samples.ipynb#X13sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m   sample_df \u001b[39m=\u001b[39m get_sample_df(df, sample)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/brendankeane/whosampled-artist/src/BTS-Samples.ipynb#X13sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m   net \u001b[39m=\u001b[39m add_sample_to_network(sample_df, net)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brendankeane/whosampled-artist/src/BTS-Samples.ipynb#X13sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mreturn\u001b[39;00m net\n",
      "\u001b[1;32m/Users/brendankeane/whosampled-artist/src/BTS-Samples.ipynb Cell 14\u001b[0m in \u001b[0;36madd_sample_to_network\u001b[0;34m(root, df)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brendankeane/whosampled-artist/src/BTS-Samples.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madd_sample_to_network\u001b[39m(root, df):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/brendankeane/whosampled-artist/src/BTS-Samples.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m   root_index \u001b[39m=\u001b[39m root[root[\u001b[39m'\u001b[39;49m\u001b[39mstyle\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m==\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mSource\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brendankeane/whosampled-artist/src/BTS-Samples.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m   \u001b[39mfor\u001b[39;00m index, row \u001b[39min\u001b[39;00m root\u001b[39m.\u001b[39miterrows():\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/brendankeane/whosampled-artist/src/BTS-Samples.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     cur_id \u001b[39m=\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/base.py:349\u001b[0m, in \u001b[0;36mIndexOpsMixin.item\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    348\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(\u001b[39mself\u001b[39m))\n\u001b[0;32m--> 349\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcan only convert an array of size 1 to a Python scalar\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: can only convert an array of size 1 to a Python scalar"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "net = pd.DataFrame(columns=['source', 'target', 'value'])\n",
    "df = pd.read_csv('data/processed/nodes_unique.csv')\n",
    "\n",
    "\n",
    "def get_sample_df(df, val):\n",
    "  rdf = df[df['sample'] == val]\n",
    "  return rdf\n",
    "\n",
    "\n",
    "def add_sample_to_network(root, df):\n",
    "  root_index = root[root['style'] == 'Source']['id'].item()\n",
    "\n",
    "  for index, row in root.iterrows():\n",
    "    cur_id = row['id']\n",
    "\n",
    "    if root_index != cur_id:\n",
    "      new_edge = pd.DataFrame({\n",
    "        'source': root_index,\n",
    "        'target': row['id'],\n",
    "        'value': [1/len(root)]\n",
    "      })\n",
    "\n",
    "      df = pd.concat([df, new_edge], ignore_index=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "def make_sample_network(df):\n",
    "  sample_list = list(set(df['sample']))\n",
    "  net = pd.DataFrame(columns=['source', 'target', 'value'])\n",
    "\n",
    "  for sample in sample_list:\n",
    "    sample_df = get_sample_df(df, sample)\n",
    "    net = add_sample_to_network(sample_df, net)\n",
    "\n",
    "  return net\n",
    "\n",
    "net = make_sample_network(df)\n",
    "net.to_csv('data/processed/edges.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Creating the visualization from the node and edge tables**\n",
    "With all nodes and edges defined, we can now create the network diagram. To do this, we will load the `nodes.csv` DataFrame and define the connections with the `edges.csv` DataFrame. The result should be an interactive network diagram consisting of all songs that share a sample with BTS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages and necessary data\n",
    "\n",
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "nodes = pd.read_csv('data/processed/nodes.csv')\n",
    "nodes.unique()\n",
    "edges = pd.read_csv('data/processed/edges.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "../index.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"../index.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x175495b70>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Network(\n",
    "  notebook=True,\n",
    ")\n",
    "nodes['label'] = nodes.apply(lambda row: '{} ({}) - {}'.format(row['title'], row['year'], row['artist']), axis=1)\n",
    "nodes['colors'] = np.where(nodes['style'] == 'Source', 'CornflowerBlue', np.where(df['artist'] == 'BTS', 'DarkOrange', 'DimGray'))\n",
    "\n",
    "titles = nodes['label'].tolist()\n",
    "labels = nodes['artist'].tolist()\n",
    "colors = nodes['colors'].tolist()\n",
    "\n",
    "net.add_nodes(nodes['id'].tolist(),\n",
    "  title=titles,\n",
    "  label=labels,\n",
    "  color=colors)\n",
    "\n",
    "for index, row in edges.iterrows():\n",
    "  net.add_edge(row['source'], row['target'], weight=row['value']*len(edges))\n",
    "\n",
    "net.show_buttons(filter_=['physics'])\n",
    "net.show('../index.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
